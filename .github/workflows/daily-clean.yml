name: Daily Netflix Reviews Clean & Upload

on:
  schedule:
    - cron: '30 2 * * *'
  workflow_dispatch:

concurrency:
  group: daily-netflix-reviews-clean-upload
  cancel-in-progress: true

jobs:
  daily:
    runs-on: ubuntu-latest
    timeout-minutes: 90

    env:
      PYTHON_VERSION: "3.10"

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: "pip"

      - name: Cache pip and spaCy caches
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/pip
            ~/.local/share/spacy
          key: ${{ runner.os }}-pip-spacy-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-spacy-

      - name: Install system dependencies
        run: |
          sudo apt-get update -y
          sudo apt-get install -y build-essential

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip wheel
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          else
            pip install kaggle gspread oauth2client google-auth google-auth-oauthlib google-auth-httplib2 gspread-dataframe vaderSentiment spacy wordcloud gensim scikit-learn nltk python-dateutil tqdm
          fi

      - name: Decode Kaggle JSON
        env:
          KAGGLE_JSON_B64: ${{ secrets.KAGGLE_JSON_B64 }}
        run: |
          if [ -z "$KAGGLE_JSON_B64" ]; then
            echo "::error::KAGGLE_JSON_B64 missing"
            exit 1
          fi
          mkdir -p ~/.kaggle
          echo "$KAGGLE_JSON_B64" | base64 --decode > ~/.kaggle/kaggle.json
          chmod 600 ~/.kaggle/kaggle.json
          echo "KAGGLE_CONFIG_DIR=$HOME/.kaggle" >> $GITHUB_ENV

      - name: Decode Google Service Account (optional)
        env:
          GCP_SA_JSON_B64: ${{ secrets.GCP_SA_JSON_B64 }}
        run: |
          if [ -z "$GCP_SA_JSON_B64" ]; then
            echo "::warning::GCP_SA_JSON_B64 missing, Sheets upload will be skipped"
          else
            echo "$GCP_SA_JSON_B64" | base64 --decode > ~/gcp_sa.json
            chmod 600 ~/gcp_sa.json
            echo "GCP_SA_FILE=$HOME/gcp_sa.json" >> $GITHUB_ENV
          fi

      - name: Export env vars
        run: |
          echo "KAGGLE_DATASET_SLUG=${{ secrets.KAGGLE_DATASET_SLUG }}" >> $GITHUB_ENV
          echo "KAGGLE_FILE_NAME=${{ secrets.KAGGLE_FILE_NAME }}" >> $GITHUB_ENV
          echo "SPREADSHEET_ID=${{ secrets.SPREADSHEET_ID }}" >> $GITHUB_ENV
          echo "SHEET_NAME=${{ secrets.SHEET_NAME }}" >> $GITHUB_ENV
          echo "OUT_CSV_PATH=$GITHUB_WORKSPACE/outputs/cleaned_reviews.csv" >> $GITHUB_ENV

      - name: Ensure outputs directory
        run: mkdir -p outputs

      - name: Install spaCy model if missing
        run: |
          python - <<EOF
import importlib, subprocess, sys
try:
    importlib.import_module("en_core_web_sm")
    print("spaCy model already present")
except ImportError:
    print("Downloading en_core_web_sm...")
    subprocess.check_call([sys.executable, "-m", "spacy", "download", "en_core_web_sm"])
EOF

      - name: Debug key files
        run: |
          ls -la ~/.kaggle || true
          ls -la ~/gcp_sa.json || true
          echo "Spreadsheet: $SPREADSHEET_ID"

      - name: Run cleaning script
        env:
          KAGGLE_CONFIG_DIR: ${{ env.KAGGLE_CONFIG_DIR }}
          GCP_SA_FILE: ${{ env.GCP_SA_FILE }}
          SPREADSHEET_ID: ${{ secrets.SPREADSHEET_ID }}
          SHEET_NAME: ${{ secrets.SHEET_NAME }}
        run: |
          if [ -z "$GCP_SA_FILE" ] || [ -z "$SPREADSHEET_ID" ]; then
            echo "Running with --no-sheets mode"
            python scripts/clean_reviews.py --no-sheets
          else
            python scripts/clean_reviews.py
          fi

      - name: Upload cleaned CSV
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: cleaned-reviews
          path: outputs/cleaned_reviews.csv
